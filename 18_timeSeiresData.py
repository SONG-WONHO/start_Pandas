from datetime import datetime
import pandas as pd
import numpy as np

#raw_data
raw_data = {'date': ['2017-05-01 18:47:05.069722',
                 '2017-05-01 18:47:05.119994',
                 '2017-05-02 18:47:05.178768',
                 '2017-05-02 18:47:05.230071',
                 '2017-05-02 18:47:05.230071',
                 '2017-05-02 18:47:05.280592',
                 '2017-05-03 18:47:05.332662',
                 '2017-05-03 18:47:05.385109',
                 '2017-05-04 18:47:05.436523',
                 '2017-05-04 18:47:05.486877'],
        'attendance': [34, 25, 26, 15, 15, 14, 26, 25, 62, 41]}

df = pd.DataFrame(raw_data, columns = ['date', 'attendance'])
'''
                         date  attendance
0  2017-05-01 18:47:05.069722          34
1  2017-05-01 18:47:05.119994          25
2  2017-05-02 18:47:05.178768          26
3  2017-05-02 18:47:05.230071          15
4  2017-05-02 18:47:05.230071          15
5  2017-05-02 18:47:05.280592          14
6  2017-05-03 18:47:05.332662          26
7  2017-05-03 18:47:05.385109          25
8  2017-05-04 18:47:05.436523          62
9  2017-05-04 18:47:05.486877          41
'''

print(type(df['date'][0])) ## <class 'str'>

#Convert df['date'] from string to datetime
df['date'] = pd.to_datetime(df['date'])

print(type(df['date'][0])) ## <class 'pandas._libs.tslib.Timestamp'>

df.set_index(df['date'], inplace= True)

#del
del df['date']

print(df)
'''
                            attendance
date                                  
2017-05-01 18:47:05.069722          34
2017-05-01 18:47:05.119994          25
2017-05-02 18:47:05.178768          26
2017-05-02 18:47:05.230071          15
2017-05-02 18:47:05.230071          15
2017-05-02 18:47:05.280592          14
2017-05-03 18:47:05.332662          26
2017-05-03 18:47:05.385109          25
2017-05-04 18:47:05.436523          62
2017-05-04 18:47:05.486877          41
'''

#View all observations under certain conditions
print(df['2017-05-01'])
'''
                            attendance
date                                  
2017-05-01 18:47:05.069722          34
2017-05-01 18:47:05.119994          25
'''

print(df[datetime(2017,5,3):])
'''
date                                  
2017-05-03 18:47:05.332662          26
2017-05-03 18:47:05.385109          25
2017-05-04 18:47:05.436523          62
2017-05-04 18:47:05.486877          41
'''

print(df['2017/5/2':])
'''
date                                  
2017-05-02 18:47:05.178768          26
2017-05-02 18:47:05.230071          15
2017-05-02 18:47:05.230071          15
2017-05-02 18:47:05.280592          14
2017-05-03 18:47:05.332662          26
2017-05-03 18:47:05.385109          25
2017-05-04 18:47:05.436523          62
2017-05-04 18:47:05.486877          41
'''

#truncate
print(df.truncate(before='2017/5/2', after='2017/5/4'))
'''
date                                  
2017-05-02 18:47:05.178768          26
2017-05-02 18:47:05.230071          15
2017-05-02 18:47:05.230071          15
2017-05-02 18:47:05.280592          14
2017-05-03 18:47:05.332662          26
2017-05-03 18:47:05.385109          25
'''

#create time
df = pd.DataFrame()

df['random_num_1'] = np.random.randint(0,100,60)
df['random_num_2'] = np.random.randint(0,100,60)
df.index = pd.date_range('1/1/2017', periods= 60, freq='H')

#Look head
print(df.head())
'''
                     random_num_1  random_num_2
2017-01-01 00:00:00            49            52
2017-01-01 01:00:00            66            11
2017-01-01 02:00:00            63            92
2017-01-01 03:00:00            22            14
2017-01-01 04:00:00             3            94
'''

#Look tail
print(df.tail())
'''
                     random_num_1  random_num_2
2017-01-03 07:00:00            39            13
2017-01-03 08:00:00            78            31
2017-01-03 09:00:00            66            74
2017-01-03 10:00:00            69            96
2017-01-03 11:00:00            25            20
'''

#shift operation
print(df.shift(1).head())
'''
                     random_num_1  random_num_2
2017-01-01 00:00:00           NaN           NaN
2017-01-01 01:00:00           1.0          97.0
2017-01-01 02:00:00          10.0          31.0
2017-01-01 03:00:00          49.0          37.0
2017-01-01 04:00:00          48.0          52.0
'''

print(df.shift(-1).tail())
'''
                     random_num_1  random_num_2
2017-01-03 07:00:00          63.0          11.0
2017-01-03 08:00:00          92.0          19.0
2017-01-03 09:00:00          70.0          52.0
2017-01-03 10:00:00          61.0          28.0
2017-01-03 11:00:00           NaN           NaN
'''

#resample
#Look sum
print(df.resample('D').sum())
'''
            random_num_1  random_num_2
2017-01-01           971          1169
2017-01-02          1070          1412
2017-01-03           688           695
'''

#Count values
print(df.resample('D').count())
'''
            random_num_1  random_num_2
2017-01-01            24            24
2017-01-02            24            24
2017-01-03            12            12
'''

#Look mean
print(df.resample('D').mean())
'''
            random_num_1  random_num_2
2017-01-01     44.708333     47.541667
2017-01-02     40.708333     40.958333
2017-01-03     56.000000     56.750000
'''

#Look median
print(df.resample('D').median())
'''
            random_num_1  random_num_2
2017-01-01          57.0          50.0
2017-01-02          52.5          65.5
2017-01-03          61.0          48.5
'''

#Look first value
print(df.resample('D').first())
'''
            random_num_1  random_num_2
2017-01-01            44            97
2017-01-02            84            79
2017-01-03            84             9
'''

#Look last value
print(df.resample('D').last())
'''
            random_num_1  random_num_2
2017-01-01             5            64
2017-01-02            91            50
2017-01-03             7            19
'''

#Look open, high, low, close values (ohlc)
print(df.resample('D').ohlc())
'''
           random_num_1                random_num_2               
                   open high low close         open high low close
2017-01-01            6   91   1    48           33   97   1    93
2017-01-02           12   96   2    27           55   94   1    73
2017-01-03            3   97   3    96           26   78  14    53
'''
